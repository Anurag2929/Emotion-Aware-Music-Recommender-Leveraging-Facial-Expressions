{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "62e794af",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T04:19:12.561401Z",
     "iopub.status.busy": "2025-11-06T04:19:12.560749Z",
     "iopub.status.idle": "2025-11-06T04:19:13.534000Z",
     "shell.execute_reply": "2025-11-06T04:19:13.533171Z"
    },
    "papermill": {
     "duration": 0.978404,
     "end_time": "2025-11-06T04:19:13.535185",
     "exception": false,
     "start_time": "2025-11-06T04:19:12.556781",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "RAF-DB Train: Collected 11566 images from /kaggle/input/emotion-datasets-rafdb-ferplus/datasets/RAF-DB/train\n",
      "FERPlus Train: Collected 14713 images from /kaggle/input/emotion-datasets-rafdb-ferplus/datasets/fer2013plus/train\n",
      "RAF-DB Test: Collected 2906 images from /kaggle/input/emotion-datasets-rafdb-ferplus/datasets/RAF-DB/test\n",
      "FERPlus Test: Collected 3721 images from /kaggle/input/emotion-datasets-rafdb-ferplus/datasets/fer2013plus/test\n",
      "\n",
      "âœ… Total merged training samples: 26279\n",
      "âœ… Total merged validation samples: 6627\n",
      "Example sample: ('/kaggle/input/emotion-datasets-rafdb-ferplus/datasets/fer2013plus/train/neutral/fer0025582.png', 4)\n"
     ]
    }
   ],
   "source": [
    "# === Block 0: Prepare merged dataset paths & class labels ===\n",
    "import glob, os, random\n",
    "\n",
    "# Emotion labels (common between both datasets)\n",
    "CLASS_LIST = ['angry', 'disgust', 'fear', 'happy', 'neutral', 'sad', 'surprise']\n",
    "\n",
    "# Dataset roots (your structure)\n",
    "BASE_DIR = \"/kaggle/input/emotion-datasets-rafdb-ferplus/datasets\"\n",
    "raf_train = os.path.join(BASE_DIR, \"RAF-DB/train\")\n",
    "raf_test  = os.path.join(BASE_DIR, \"RAF-DB/test\")\n",
    "fer_train = os.path.join(BASE_DIR, \"fer2013plus/train\")\n",
    "fer_test  = os.path.join(BASE_DIR, \"fer2013plus/test\")\n",
    "\n",
    "def collect_images(base_path, dataset_name):\n",
    "    collected = []\n",
    "    for idx, emotion in enumerate(CLASS_LIST):\n",
    "        # Match both lower/upper folder names\n",
    "        for folder_name in [emotion, emotion.capitalize()]:\n",
    "            pattern_jpg = os.path.join(base_path, folder_name, \"*.jpg\")\n",
    "            pattern_png = os.path.join(base_path, folder_name, \"*.png\")\n",
    "            pattern_jpeg = os.path.join(base_path, folder_name, \"*.jpeg\")\n",
    "            for path in glob.glob(pattern_jpg) + glob.glob(pattern_png) + glob.glob(pattern_jpeg):\n",
    "                collected.append((path, idx))\n",
    "    print(f\"{dataset_name}: Collected {len(collected)} images from {base_path}\")\n",
    "    return collected\n",
    "\n",
    "# Collect from both datasets\n",
    "image_paths = collect_images(raf_train, \"RAF-DB Train\") + collect_images(fer_train, \"FERPlus Train\")\n",
    "val_paths   = collect_images(raf_test, \"RAF-DB Test\") + collect_images(fer_test, \"FERPlus Test\")\n",
    "\n",
    "# Shuffle the dataset\n",
    "random.shuffle(image_paths)\n",
    "random.shuffle(val_paths)\n",
    "\n",
    "print(f\"\\nâœ… Total merged training samples: {len(image_paths)}\")\n",
    "print(f\"âœ… Total merged validation samples: {len(val_paths)}\")\n",
    "if len(image_paths) > 0:\n",
    "    print(\"Example sample:\", image_paths[0])\n",
    "else:\n",
    "    print(\"âš ï¸ No images found â€” check dataset mount path or file types!\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ff4265e9",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T04:19:13.541208Z",
     "iopub.status.busy": "2025-11-06T04:19:13.540526Z",
     "iopub.status.idle": "2025-11-06T04:19:41.357820Z",
     "shell.execute_reply": "2025-11-06T04:19:41.356927Z"
    },
    "papermill": {
     "duration": 27.821539,
     "end_time": "2025-11-06T04:19:41.359226",
     "exception": false,
     "start_time": "2025-11-06T04:19:13.537687",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-11-06 04:19:16.754821: E external/local_xla/xla/stream_executor/cuda/cuda_fft.cc:477] Unable to register cuFFT factory: Attempting to register factory for plugin cuFFT when one has already been registered\n",
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "E0000 00:00:1762402757.178126      19 cuda_dnn.cc:8310] Unable to register cuDNN factory: Attempting to register factory for plugin cuDNN when one has already been registered\n",
      "E0000 00:00:1762402757.296330      19 cuda_blas.cc:1418] Unable to register cuBLAS factory: Attempting to register factory for plugin cuBLAS when one has already been registered\n",
      "I0000 00:00:1762402778.541043      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:0 with 13942 MB memory:  -> device: 0, name: Tesla T4, pci bus id: 0000:00:04.0, compute capability: 7.5\n",
      "I0000 00:00:1762402778.541899      19 gpu_device.cc:2022] Created device /job:localhost/replica:0/task:0/device:GPU:1 with 13942 MB memory:  -> device: 1, name: Tesla T4, pci bus id: 0000:00:05.0, compute capability: 7.5\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Batch shape: (32, 224, 224, 3) dtype: <dtype: 'float32'>\n",
      "Labels shape: (32,) dtype: <dtype: 'int32'>\n"
     ]
    }
   ],
   "source": [
    "# === Block 1: Build TensorFlow datasets ===\n",
    "import tensorflow as tf\n",
    "\n",
    "IMG_SIZE = (224, 224)\n",
    "BATCH_SIZE = 32\n",
    "AUTO = tf.data.AUTOTUNE\n",
    "SEED = 42\n",
    "\n",
    "# --- Keras augmentation layers (TF-native, fast, GPU-accelerated) ---\n",
    "augment_layers = tf.keras.Sequential([\n",
    "    tf.keras.layers.RandomFlip(\"horizontal\"),\n",
    "    tf.keras.layers.RandomRotation(0.1),\n",
    "    tf.keras.layers.RandomContrast(0.1),\n",
    "    tf.keras.layers.RandomBrightness(factor=0.08),\n",
    "])\n",
    "\n",
    "def load_and_preprocess(path, label, augment=False):\n",
    "    # Decode & resize\n",
    "    img = tf.io.read_file(path)\n",
    "    img = tf.image.decode_jpeg(img, channels=3)\n",
    "    img = tf.image.resize(img, IMG_SIZE)\n",
    "    img = tf.cast(img, tf.float32) / 255.0\n",
    "\n",
    "    # Apply augmentation if enabled\n",
    "    if augment:\n",
    "        img = augment_layers(img)\n",
    "    return img, label\n",
    "\n",
    "def make_dataset(image_label_pairs, augment=False):\n",
    "    paths = [p for p, _ in image_label_pairs]\n",
    "    labels = [l for _, l in image_label_pairs]\n",
    "\n",
    "    ds = tf.data.Dataset.from_tensor_slices((paths, labels))\n",
    "    if augment:\n",
    "        ds = ds.shuffle(buffer_size=4096, seed=SEED)\n",
    "    ds = ds.map(lambda p, l: load_and_preprocess(p, l, augment), num_parallel_calls=AUTO)\n",
    "    ds = ds.batch(BATCH_SIZE).prefetch(AUTO)\n",
    "    return ds\n",
    "\n",
    "# âœ… Create the datasets\n",
    "train_ds = make_dataset(image_paths, augment=True)\n",
    "val_ds   = make_dataset(val_paths, augment=False)\n",
    "\n",
    "# --- Quick sanity check ---\n",
    "for x_batch, y_batch in train_ds.take(1):\n",
    "    print(\"Batch shape:\", x_batch.shape, \"dtype:\", x_batch.dtype)\n",
    "    print(\"Labels shape:\", y_batch.shape, \"dtype:\", y_batch.dtype)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3f47c103",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T04:19:41.364521Z",
     "iopub.status.busy": "2025-11-06T04:19:41.364284Z",
     "iopub.status.idle": "2025-11-06T04:19:43.992427Z",
     "shell.execute_reply": "2025-11-06T04:19:43.991871Z"
    },
    "papermill": {
     "duration": 2.631846,
     "end_time": "2025-11-06T04:19:43.993435",
     "exception": false,
     "start_time": "2025-11-06T04:19:41.361589",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Downloading data from https://storage.googleapis.com/tensorflow/keras-applications/resnet/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5\n",
      "\u001b[1m94765736/94765736\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 0us/step\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"functional_2\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"functional_2\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ<span style=\"font-weight: bold\"> Layer (type)        </span>â”ƒ<span style=\"font-weight: bold\"> Output Shape      </span>â”ƒ<span style=\"font-weight: bold\">    Param # </span>â”ƒ<span style=\"font-weight: bold\"> Connected to      </span>â”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_2       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">224</span>,  â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ -                 â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">InputLayer</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">3</span>)                â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ resnet50            â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> â”‚ input_layer_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ resnet50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_max_poolingâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ resnet50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalMaxPooling2â€¦</span> â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential_1        â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,      â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">1,050,880</span> â”‚ global_average_pâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Sequential</span>)        â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚ global_max_pooliâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Add</span>)           â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>,      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ sequential_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚ sequential_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">â€¦</span> â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multiply (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ resnet50[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   â”‚\n",
       "â”‚                     â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚ add[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]         â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lambda (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lambda_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Lambda</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate         â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ lambda[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],     â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ lambda_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Conv2D</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>)   â”‚         <span style=\"color: #00af00; text-decoration-color: #00af00\">99</span> â”‚ concatenate[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multiply_1          â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>,      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multiply[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],   â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Multiply</span>)          â”‚ <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)             â”‚            â”‚ conv2d[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]      â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multiply_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]  â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">GlobalAveragePoolâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ reshape (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Reshape</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)   â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ global_average_pâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)   â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,099,968</span> â”‚ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>],    â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">MultiHeadAttentioâ€¦</span> â”‚                   â”‚            â”‚ reshape[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)   â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate_1       â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4096</span>)      â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ global_average_pâ€¦ â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Concatenate</span>)       â”‚                   â”‚            â”‚ flatten[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚  <span style=\"color: #00af00; text-decoration-color: #00af00\">2,097,664</span> â”‚ concatenate_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">2,048</span> â”‚ dense_2[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]     â”‚\n",
       "â”‚ (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">BatchNormalizatioâ€¦</span> â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>) â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)       â”‚          <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)     â”‚ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">7</span>)         â”‚      <span style=\"color: #00af00; text-decoration-color: #00af00\">3,591</span> â”‚ dropout_1[<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>][<span style=\"color: #00af00; text-decoration-color: #00af00\">0</span>]   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n",
       "</pre>\n"
      ],
      "text/plain": [
       "â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”³â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”“\n",
       "â”ƒ\u001b[1m \u001b[0m\u001b[1mLayer (type)       \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mOutput Shape     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1m   Param #\u001b[0m\u001b[1m \u001b[0mâ”ƒ\u001b[1m \u001b[0m\u001b[1mConnected to     \u001b[0m\u001b[1m \u001b[0mâ”ƒ\n",
       "â”¡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â•‡â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”©\n",
       "â”‚ input_layer_2       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m224\u001b[0m, \u001b[38;5;34m224\u001b[0m,  â”‚          \u001b[38;5;34m0\u001b[0m â”‚ -                 â”‚\n",
       "â”‚ (\u001b[38;5;33mInputLayer\u001b[0m)        â”‚ \u001b[38;5;34m3\u001b[0m)                â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ resnet50            â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      â”‚ \u001b[38;5;34m23,587,712\u001b[0m â”‚ input_layer_2[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mFunctional\u001b[0m)        â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ resnet50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_max_poolingâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ resnet50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalMaxPooling2â€¦\u001b[0m â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ sequential_1        â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,      â”‚  \u001b[38;5;34m1,050,880\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mSequential\u001b[0m)        â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚ global_max_pooliâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ add (\u001b[38;5;33mAdd\u001b[0m)           â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m1\u001b[0m,      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ sequential_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚ sequential_1[\u001b[38;5;34m1\u001b[0m][\u001b[38;5;34mâ€¦\u001b[0m â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multiply (\u001b[38;5;33mMultiply\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ resnet50[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   â”‚\n",
       "â”‚                     â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚ add[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]         â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lambda (\u001b[38;5;33mLambda\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ lambda_1 (\u001b[38;5;33mLambda\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate         â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m2\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ lambda[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],     â”‚\n",
       "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ lambda_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]    â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ conv2d (\u001b[38;5;33mConv2D\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m1\u001b[0m)   â”‚         \u001b[38;5;34m99\u001b[0m â”‚ concatenate[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m] â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multiply_1          â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m, \u001b[38;5;34m7\u001b[0m,      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multiply[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],   â”‚\n",
       "â”‚ (\u001b[38;5;33mMultiply\u001b[0m)          â”‚ \u001b[38;5;34m2048\u001b[0m)             â”‚            â”‚ conv2d[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]      â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ global_average_pooâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multiply_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]  â”‚\n",
       "â”‚ (\u001b[38;5;33mGlobalAveragePoolâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ reshape (\u001b[38;5;33mReshape\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)   â”‚          \u001b[38;5;34m0\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ multi_head_attentiâ€¦ â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1\u001b[0m, \u001b[38;5;34m2048\u001b[0m)   â”‚  \u001b[38;5;34m2,099,968\u001b[0m â”‚ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m],    â”‚\n",
       "â”‚ (\u001b[38;5;33mMultiHeadAttentioâ€¦\u001b[0m â”‚                   â”‚            â”‚ reshape[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ flatten (\u001b[38;5;33mFlatten\u001b[0m)   â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ multi_head_attenâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ concatenate_1       â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4096\u001b[0m)      â”‚          \u001b[38;5;34m0\u001b[0m â”‚ global_average_pâ€¦ â”‚\n",
       "â”‚ (\u001b[38;5;33mConcatenate\u001b[0m)       â”‚                   â”‚            â”‚ flatten[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_2 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚  \u001b[38;5;34m2,097,664\u001b[0m â”‚ concatenate_1[\u001b[38;5;34m0\u001b[0m]â€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ batch_normalization â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚      \u001b[38;5;34m2,048\u001b[0m â”‚ dense_2[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]     â”‚\n",
       "â”‚ (\u001b[38;5;33mBatchNormalizatioâ€¦\u001b[0m â”‚                   â”‚            â”‚                   â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dropout_1 (\u001b[38;5;33mDropout\u001b[0m) â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)       â”‚          \u001b[38;5;34m0\u001b[0m â”‚ batch_normalizatâ€¦ â”‚\n",
       "â”œâ”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¼â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”¤\n",
       "â”‚ dense_3 (\u001b[38;5;33mDense\u001b[0m)     â”‚ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m7\u001b[0m)         â”‚      \u001b[38;5;34m3,591\u001b[0m â”‚ dropout_1[\u001b[38;5;34m0\u001b[0m][\u001b[38;5;34m0\u001b[0m]   â”‚\n",
       "â””â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”´â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”€â”˜\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">28,841,962</span> (110.02 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m28,841,962\u001b[0m (110.02 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">5,253,226</span> (20.04 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m5,253,226\u001b[0m (20.04 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,588,736</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,588,736\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# === Block 2: Model (ResNet50 + CBAM + Multi-Head Attention) ===\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import layers, models\n",
    "from tensorflow.keras.applications import ResNet50\n",
    "\n",
    "# --- CBAM (Channel + Spatial Attention) ---\n",
    "def cbam_block(x, reduction=8):\n",
    "    ch = x.shape[-1]\n",
    "\n",
    "    # Channel attention\n",
    "    avg_pool = layers.GlobalAveragePooling2D(keepdims=True)(x)\n",
    "    max_pool = layers.GlobalMaxPooling2D(keepdims=True)(x)\n",
    "\n",
    "    shared_mlp = tf.keras.Sequential([\n",
    "        layers.Dense(ch // reduction, activation='relu'),\n",
    "        layers.Dense(ch, activation='sigmoid')\n",
    "    ])\n",
    "\n",
    "    attn_channel = layers.Add()([shared_mlp(avg_pool), shared_mlp(max_pool)])\n",
    "    x = layers.Multiply()([x, attn_channel])\n",
    "\n",
    "    # Spatial attention (use Keras layers instead of tf ops)\n",
    "    avg_spatial = layers.Lambda(lambda t: tf.reduce_mean(t, axis=-1, keepdims=True))(x)\n",
    "    max_spatial = layers.Lambda(lambda t: tf.reduce_max(t, axis=-1, keepdims=True))(x)\n",
    "    concat = layers.Concatenate(axis=-1)([avg_spatial, max_spatial])\n",
    "    spat_attn = layers.Conv2D(1, 7, padding='same', activation='sigmoid')(concat)\n",
    "    x = layers.Multiply()([x, spat_attn])\n",
    "    return x\n",
    "\n",
    "# --- Model builder ---\n",
    "def build_model(input_shape=(224, 224, 3), num_classes=len(CLASS_LIST)):\n",
    "    base = ResNet50(include_top=False, weights='imagenet', input_shape=input_shape)\n",
    "    base.trainable = False\n",
    "\n",
    "    inp = layers.Input(shape=input_shape)\n",
    "    x = base(inp, training=False)\n",
    "    x = cbam_block(x)\n",
    "    x = layers.GlobalAveragePooling2D()(x)\n",
    "\n",
    "    # Multi-Head Attention block\n",
    "    seq = layers.Reshape((1, x.shape[-1]))(x)\n",
    "    attn = layers.MultiHeadAttention(num_heads=4, key_dim=64)(seq, seq)\n",
    "    attn = layers.Flatten()(attn)\n",
    "\n",
    "    # Combine attention outputs\n",
    "    x = layers.Concatenate()([x, attn])\n",
    "    x = layers.Dense(512, activation='relu')(x)\n",
    "    x = layers.BatchNormalization()(x)\n",
    "    x = layers.Dropout(0.4)(x)\n",
    "    out = layers.Dense(num_classes, activation='softmax')(x)\n",
    "\n",
    "    return models.Model(inp, out)\n",
    "\n",
    "# âœ… Build & summarize\n",
    "model = build_model()\n",
    "model.summary()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "5cf7fe58",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T04:19:44.001473Z",
     "iopub.status.busy": "2025-11-06T04:19:44.001233Z",
     "iopub.status.idle": "2025-11-06T05:57:22.658037Z",
     "shell.execute_reply": "2025-11-06T05:57:22.657279Z"
    },
    "papermill": {
     "duration": 5858.662218,
     "end_time": "2025-11-06T05:57:22.659221",
     "exception": false,
     "start_time": "2025-11-06T04:19:43.997003",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "âœ… Class weights: {1: 4.823604992657856, 2: 4.694355126831011, 3: 0.9178192232467169, 4: 0.3413211762261014, 5: 2.2098049108644466, 6: 0.9026861775212971}\n",
      "ğŸš€ Phase 1: Training frozen base...\n",
      "Epoch 1/15\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING: All log messages before absl::InitializeLog() is called are written to STDERR\n",
      "I0000 00:00:1762402797.843260      61 service.cc:148] XLA service 0x7ac640001c70 initialized for platform CUDA (this does not guarantee that XLA will be used). Devices:\n",
      "I0000 00:00:1762402797.844597      61 service.cc:156]   StreamExecutor device (0): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1762402797.844615      61 service.cc:156]   StreamExecutor device (1): Tesla T4, Compute Capability 7.5\n",
      "I0000 00:00:1762402800.164262      61 cuda_dnn.cc:529] Loaded cuDNN version 90300\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  1/822\u001b[0m \u001b[37mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m \u001b[1m5:29:03\u001b[0m 24s/step - accuracy: 0.2500 - loss: 1.8324"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "I0000 00:00:1762402808.012407      61 device_compiler.h:188] Compiled cluster using XLA!  This line is logged at most once for the lifetime of the process.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 231ms/step - accuracy: 0.1875 - loss: 1.9203\n",
      "Epoch 1: val_accuracy improved from -inf to 0.19647, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_best.keras\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m242s\u001b[0m 265ms/step - accuracy: 0.1875 - loss: 1.9202 - val_accuracy: 0.1965 - val_loss: 2.6863 - learning_rate: 1.0000e-04\n",
      "Epoch 2/15\n",
      "\u001b[1m821/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.2967 - loss: 1.7121\n",
      "Epoch 2: val_accuracy improved from 0.19647 to 0.21609, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_best.keras\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m159s\u001b[0m 193ms/step - accuracy: 0.2968 - loss: 1.7121 - val_accuracy: 0.2161 - val_loss: 5.4500 - learning_rate: 1.0000e-04\n",
      "Epoch 3/15\n",
      "\u001b[1m821/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.3349 - loss: 1.6969\n",
      "Epoch 3: val_accuracy improved from 0.21609 to 0.26769, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_best.keras\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 191ms/step - accuracy: 0.3349 - loss: 1.6968 - val_accuracy: 0.2677 - val_loss: 2.0761 - learning_rate: 1.0000e-04\n",
      "Epoch 4/15\n",
      "\u001b[1m821/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 170ms/step - accuracy: 0.3184 - loss: 1.6543\n",
      "Epoch 4: val_accuracy did not improve from 0.26769\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 191ms/step - accuracy: 0.3184 - loss: 1.6542 - val_accuracy: 0.1909 - val_loss: 4.3061 - learning_rate: 1.0000e-04\n",
      "Epoch 5/15\n",
      "\u001b[1m821/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.3360 - loss: 1.6491\n",
      "Epoch 5: val_accuracy did not improve from 0.26769\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 189ms/step - accuracy: 0.3360 - loss: 1.6491 - val_accuracy: 0.1188 - val_loss: 5.6976 - learning_rate: 1.0000e-04\n",
      "Epoch 6/15\n",
      "\u001b[1m821/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.3473 - loss: 1.6332\n",
      "Epoch 6: ReduceLROnPlateau reducing learning rate to 2.9999999242136255e-05.\n",
      "\n",
      "Epoch 6: val_accuracy did not improve from 0.26769\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 189ms/step - accuracy: 0.3473 - loss: 1.6332 - val_accuracy: 0.1827 - val_loss: 9.6175 - learning_rate: 1.0000e-04\n",
      "Epoch 7/15\n",
      "\u001b[1m821/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.3691 - loss: 1.6152\n",
      "Epoch 7: val_accuracy improved from 0.26769 to 0.30572, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_best.keras\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 191ms/step - accuracy: 0.3691 - loss: 1.6151 - val_accuracy: 0.3057 - val_loss: 2.4997 - learning_rate: 3.0000e-05\n",
      "Epoch 8/15\n",
      "\u001b[1m821/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.3706 - loss: 1.6120\n",
      "Epoch 8: val_accuracy did not improve from 0.30572\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 189ms/step - accuracy: 0.3706 - loss: 1.6120 - val_accuracy: 0.2552 - val_loss: 1.7821 - learning_rate: 3.0000e-05\n",
      "Epoch 9/15\n",
      "\u001b[1m821/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 168ms/step - accuracy: 0.3622 - loss: 1.5917\n",
      "Epoch 9: val_accuracy improved from 0.30572 to 0.43247, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_best.keras\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m157s\u001b[0m 191ms/step - accuracy: 0.3622 - loss: 1.5917 - val_accuracy: 0.4325 - val_loss: 1.4321 - learning_rate: 3.0000e-05\n",
      "Epoch 10/15\n",
      "\u001b[1m821/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.3583 - loss: 1.5927\n",
      "Epoch 10: val_accuracy did not improve from 0.43247\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 188ms/step - accuracy: 0.3583 - loss: 1.5927 - val_accuracy: 0.2804 - val_loss: 2.0215 - learning_rate: 3.0000e-05\n",
      "Epoch 11/15\n",
      "\u001b[1m821/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.3563 - loss: 1.5851\n",
      "Epoch 11: val_accuracy improved from 0.43247 to 0.60254, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_best.keras\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m156s\u001b[0m 189ms/step - accuracy: 0.3563 - loss: 1.5851 - val_accuracy: 0.6025 - val_loss: 1.1389 - learning_rate: 3.0000e-05\n",
      "Epoch 12/15\n",
      "\u001b[1m821/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.3727 - loss: 1.5914\n",
      "Epoch 12: val_accuracy did not improve from 0.60254\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 189ms/step - accuracy: 0.3727 - loss: 1.5914 - val_accuracy: 0.2929 - val_loss: 2.1109 - learning_rate: 3.0000e-05\n",
      "Epoch 13/15\n",
      "\u001b[1m821/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.3693 - loss: 1.5816\n",
      "Epoch 13: val_accuracy did not improve from 0.60254\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 189ms/step - accuracy: 0.3693 - loss: 1.5816 - val_accuracy: 0.1787 - val_loss: 5.6292 - learning_rate: 3.0000e-05\n",
      "Epoch 14/15\n",
      "\u001b[1m821/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.3682 - loss: 1.5860\n",
      "Epoch 14: ReduceLROnPlateau reducing learning rate to 8.999999772640877e-06.\n",
      "\n",
      "Epoch 14: val_accuracy did not improve from 0.60254\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 189ms/step - accuracy: 0.3682 - loss: 1.5860 - val_accuracy: 0.4302 - val_loss: 1.3408 - learning_rate: 3.0000e-05\n",
      "Epoch 15/15\n",
      "\u001b[1m821/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37mâ”\u001b[0m \u001b[1m0s\u001b[0m 167ms/step - accuracy: 0.3663 - loss: 1.5658\n",
      "Epoch 15: val_accuracy did not improve from 0.60254\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m155s\u001b[0m 189ms/step - accuracy: 0.3663 - loss: 1.5658 - val_accuracy: 0.4518 - val_loss: 1.4147 - learning_rate: 9.0000e-06\n",
      "Restoring model weights from the end of the best epoch: 11.\n",
      "\n",
      "ğŸ”“ Phase 2: Fine-tuning top 30 layers...\n",
      "\n",
      "ğŸš€ Phase 2: Training fine-tuned model...\n",
      "Epoch 1/10\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 408ms/step - accuracy: 0.2307 - loss: 3.0127\n",
      "Epoch 1: val_accuracy improved from -inf to 0.21971, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_finetuned.keras\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m442s\u001b[0m 441ms/step - accuracy: 0.2307 - loss: 3.0121 - val_accuracy: 0.2197 - val_loss: 2.0119 - learning_rate: 1.0000e-05\n",
      "Epoch 2/10\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.2502 - loss: 1.9147\n",
      "Epoch 2: val_accuracy improved from 0.21971 to 0.35642, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_finetuned.keras\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m335s\u001b[0m 407ms/step - accuracy: 0.2502 - loss: 1.9147 - val_accuracy: 0.3564 - val_loss: 1.7210 - learning_rate: 1.0000e-05\n",
      "Epoch 3/10\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.2761 - loss: 1.7803\n",
      "Epoch 3: val_accuracy improved from 0.35642 to 0.38901, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_finetuned.keras\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 406ms/step - accuracy: 0.2761 - loss: 1.7803 - val_accuracy: 0.3890 - val_loss: 1.7025 - learning_rate: 1.0000e-05\n",
      "Epoch 4/10\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.2943 - loss: 1.7568\n",
      "Epoch 4: val_accuracy improved from 0.38901 to 0.46341, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_finetuned.keras\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 405ms/step - accuracy: 0.2943 - loss: 1.7568 - val_accuracy: 0.4634 - val_loss: 1.5525 - learning_rate: 1.0000e-05\n",
      "Epoch 5/10\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.3084 - loss: 1.6964\n",
      "Epoch 5: val_accuracy improved from 0.46341 to 0.54218, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_finetuned.keras\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 403ms/step - accuracy: 0.3084 - loss: 1.6964 - val_accuracy: 0.5422 - val_loss: 1.3672 - learning_rate: 1.0000e-05\n",
      "Epoch 6/10\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.3163 - loss: 1.6486\n",
      "Epoch 6: val_accuracy improved from 0.54218 to 0.59831, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_finetuned.keras\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 404ms/step - accuracy: 0.3163 - loss: 1.6486 - val_accuracy: 0.5983 - val_loss: 1.2751 - learning_rate: 1.0000e-05\n",
      "Epoch 7/10\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 379ms/step - accuracy: 0.3394 - loss: 1.6210\n",
      "Epoch 7: val_accuracy improved from 0.59831 to 0.65128, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_finetuned.keras\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 404ms/step - accuracy: 0.3394 - loss: 1.6210 - val_accuracy: 0.6513 - val_loss: 1.0870 - learning_rate: 1.0000e-05\n",
      "Epoch 8/10\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.3544 - loss: 1.5289\n",
      "Epoch 8: val_accuracy did not improve from 0.65128\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m331s\u001b[0m 402ms/step - accuracy: 0.3544 - loss: 1.5289 - val_accuracy: 0.6445 - val_loss: 1.0921 - learning_rate: 1.0000e-05\n",
      "Epoch 9/10\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.3651 - loss: 1.5282\n",
      "Epoch 9: val_accuracy did not improve from 0.65128\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m330s\u001b[0m 401ms/step - accuracy: 0.3651 - loss: 1.5281 - val_accuracy: 0.6194 - val_loss: 1.0935 - learning_rate: 1.0000e-05\n",
      "Epoch 10/10\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 380ms/step - accuracy: 0.3771 - loss: 1.5026\n",
      "Epoch 10: val_accuracy improved from 0.65128 to 0.67602, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_finetuned.keras\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 405ms/step - accuracy: 0.3771 - loss: 1.5026 - val_accuracy: 0.6760 - val_loss: 0.9334 - learning_rate: 1.0000e-05\n",
      "Restoring model weights from the end of the best epoch: 10.\n",
      "\n",
      "âœ… Training complete. Model saved to: /kaggle/working/checkpoints/resnet50_cbam_mha_finetuned.keras\n"
     ]
    }
   ],
   "source": [
    "# === Block 3: Two-Phase Training (Frozen + Fine-tune) ===\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ReduceLROnPlateau, ModelCheckpoint\n",
    "import numpy as np, os\n",
    "\n",
    "# --- Compute class weights directly from your integer labels ---\n",
    "train_labels = [lbl for _, lbl in image_paths]\n",
    "unique_labels = np.unique(train_labels)\n",
    "cw = compute_class_weight(class_weight=\"balanced\", classes=unique_labels, y=train_labels)\n",
    "class_weights = {int(label): float(weight) for label, weight in zip(unique_labels, cw)}\n",
    "print(\"âœ… Class weights:\", class_weights)\n",
    "\n",
    "# --- Compile model for sparse labels ---\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy()\n",
    "opt = tf.keras.optimizers.Adam(learning_rate=1e-4)\n",
    "model.compile(optimizer=opt, loss=loss_fn, metrics=[\"accuracy\"])\n",
    "\n",
    "# --- Checkpoint setup ---\n",
    "CKPT_DIR = \"/kaggle/working/checkpoints\"\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "MODEL_SAVE = os.path.join(CKPT_DIR, \"resnet50_cbam_mha_best.keras\")\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor=\"val_accuracy\", patience=6, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.3, patience=3, min_lr=1e-6, verbose=1),\n",
    "    ModelCheckpoint(MODEL_SAVE, monitor=\"val_accuracy\", save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "# === Phase 1: Train top (frozen) layers ===\n",
    "print(\"ğŸš€ Phase 1: Training frozen base...\")\n",
    "history1 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=15,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# === Phase 2: Fine-tune deeper layers ===\n",
    "print(\"\\nğŸ”“ Phase 2: Fine-tuning top 30 layers...\")\n",
    "for layer in model.layers[-30:]:\n",
    "    if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        layer.trainable = True\n",
    "\n",
    "opt_fine = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "model.compile(optimizer=opt_fine, loss=loss_fn, metrics=[\"accuracy\"])\n",
    "\n",
    "MODEL_SAVE_FINE = os.path.join(CKPT_DIR, \"resnet50_cbam_mha_finetuned.keras\")\n",
    "callbacks_fine = [\n",
    "    EarlyStopping(monitor=\"val_accuracy\", patience=8, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor=\"val_loss\", factor=0.5, patience=4, min_lr=1e-7, verbose=1),\n",
    "    ModelCheckpoint(MODEL_SAVE_FINE, monitor=\"val_accuracy\", save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "print(\"\\nğŸš€ Phase 2: Training fine-tuned model...\")\n",
    "history2 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks_fine\n",
    ")\n",
    "\n",
    "print(f\"\\nâœ… Training complete. Model saved to: {MODEL_SAVE_FINE}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "5094185f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T05:57:24.502406Z",
     "iopub.status.busy": "2025-11-06T05:57:24.502120Z",
     "iopub.status.idle": "2025-11-06T06:56:39.744013Z",
     "shell.execute_reply": "2025-11-06T06:56:39.743264Z"
    },
    "papermill": {
     "duration": 3557.383463,
     "end_time": "2025-11-06T06:56:40.908625",
     "exception": false,
     "start_time": "2025-11-06T05:57:23.525162",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸš€ Phase 3: Deep fine-tuning (unfreeze top 80 layers)...\n",
      "Epoch 1/10\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 405ms/step - accuracy: 0.3948 - loss: 1.4335\n",
      "Epoch 1: val_accuracy improved from -inf to 0.67421, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_deep_finetuned.keras\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m431s\u001b[0m 437ms/step - accuracy: 0.3948 - loss: 1.4335 - val_accuracy: 0.6742 - val_loss: 0.9316 - learning_rate: 5.0000e-06\n",
      "Epoch 2/10\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.3899 - loss: 1.4363\n",
      "Epoch 2: val_accuracy improved from 0.67421 to 0.68643, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_deep_finetuned.keras\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 406ms/step - accuracy: 0.3899 - loss: 1.4363 - val_accuracy: 0.6864 - val_loss: 0.8919 - learning_rate: 5.0000e-06\n",
      "Epoch 3/10\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 381ms/step - accuracy: 0.4057 - loss: 1.3963\n",
      "Epoch 3: val_accuracy improved from 0.68643 to 0.71510, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_deep_finetuned.keras\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 405ms/step - accuracy: 0.4057 - loss: 1.3963 - val_accuracy: 0.7151 - val_loss: 0.8431 - learning_rate: 5.0000e-06\n",
      "Epoch 4/10\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 490ms/step - accuracy: 0.4150 - loss: 1.3906\n",
      "Epoch 4: val_accuracy improved from 0.71510 to 0.72778, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_deep_finetuned.keras\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m430s\u001b[0m 524ms/step - accuracy: 0.4150 - loss: 1.3906 - val_accuracy: 0.7278 - val_loss: 0.7824 - learning_rate: 5.0000e-06\n",
      "Epoch 5/10\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 419ms/step - accuracy: 0.4147 - loss: 1.3559\n",
      "Epoch 5: val_accuracy did not improve from 0.72778\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m362s\u001b[0m 440ms/step - accuracy: 0.4147 - loss: 1.3559 - val_accuracy: 0.7186 - val_loss: 0.7940 - learning_rate: 5.0000e-06\n",
      "Epoch 6/10\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 383ms/step - accuracy: 0.4214 - loss: 1.3489\n",
      "Epoch 6: val_accuracy did not improve from 0.72778\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m333s\u001b[0m 405ms/step - accuracy: 0.4214 - loss: 1.3489 - val_accuracy: 0.6916 - val_loss: 0.8818 - learning_rate: 5.0000e-06\n",
      "Epoch 7/10\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.4297 - loss: 1.3464\n",
      "Epoch 7: ReduceLROnPlateau reducing learning rate to 2.499999936844688e-06.\n",
      "\n",
      "Epoch 7: val_accuracy did not improve from 0.72778\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 403ms/step - accuracy: 0.4297 - loss: 1.3463 - val_accuracy: 0.6825 - val_loss: 0.8945 - learning_rate: 5.0000e-06\n",
      "Epoch 8/10\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.4433 - loss: 1.2998\n",
      "Epoch 8: val_accuracy improved from 0.72778 to 0.73502, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_deep_finetuned.keras\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 406ms/step - accuracy: 0.4433 - loss: 1.2998 - val_accuracy: 0.7350 - val_loss: 0.7567 - learning_rate: 2.5000e-06\n",
      "Epoch 9/10\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.4312 - loss: 1.3304\n",
      "Epoch 9: val_accuracy improved from 0.73502 to 0.74876, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_deep_finetuned.keras\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 406ms/step - accuracy: 0.4312 - loss: 1.3304 - val_accuracy: 0.7488 - val_loss: 0.7097 - learning_rate: 2.5000e-06\n",
      "Epoch 10/10\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 382ms/step - accuracy: 0.4386 - loss: 1.3004\n",
      "Epoch 10: val_accuracy did not improve from 0.74876\n",
      "\u001b[1m822/822\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m332s\u001b[0m 404ms/step - accuracy: 0.4386 - loss: 1.3004 - val_accuracy: 0.7236 - val_loss: 0.7659 - learning_rate: 2.5000e-06\n",
      "Restoring model weights from the end of the best epoch: 9.\n",
      "âœ… Deep fine-tuning complete! Final model saved to: /kaggle/working/checkpoints/resnet50_cbam_mha_deep_finetuned.keras\n"
     ]
    }
   ],
   "source": [
    "# === Phase 3: Extended fine-tuning for higher accuracy ===\n",
    "print(\"\\nğŸš€ Phase 3: Deep fine-tuning (unfreeze top 80 layers)...\")\n",
    "\n",
    "for layer in model.layers[-80:]:\n",
    "    if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        layer.trainable = True\n",
    "\n",
    "opt_deep = tf.keras.optimizers.Adam(learning_rate=5e-6)\n",
    "model.compile(optimizer=opt_deep, loss=tf.keras.losses.SparseCategoricalCrossentropy(), metrics=['accuracy'])\n",
    "\n",
    "MODEL_SAVE_DEEP = os.path.join(CKPT_DIR, \"resnet50_cbam_mha_deep_finetuned.keras\")\n",
    "callbacks_deep = [\n",
    "    EarlyStopping(monitor='val_accuracy', patience=5, restore_best_weights=True, verbose=1),\n",
    "    ReduceLROnPlateau(monitor='val_loss', factor=0.5, patience=3, min_lr=1e-7, verbose=1),\n",
    "    ModelCheckpoint(MODEL_SAVE_DEEP, monitor='val_accuracy', save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "history3 = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=10,\n",
    "    class_weight=class_weights,\n",
    "    callbacks=callbacks_deep\n",
    ")\n",
    "\n",
    "print(f\"âœ… Deep fine-tuning complete! Final model saved to: {MODEL_SAVE_DEEP}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "7c8db59f",
   "metadata": {
    "execution": {
     "iopub.execute_input": "2025-11-06T06:56:43.501254Z",
     "iopub.status.busy": "2025-11-06T06:56:43.500646Z",
     "iopub.status.idle": "2025-11-06T09:44:48.165135Z",
     "shell.execute_reply": "2025-11-06T09:44:48.164358Z"
    },
    "papermill": {
     "duration": 10091.023749,
     "end_time": "2025-11-06T09:44:53.174151",
     "exception": false,
     "start_time": "2025-11-06T06:56:42.150402",
     "status": "completed"
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ğŸš€ Starting Final Fine-Tuning for ResNet50 CBAM MHA Model\n",
      "âœ… Mixed precision enabled.\n",
      "ğŸ”“ Unfroze top 40 layers for fine-tuning\n",
      "âœ… Model recompiled with Adam (1e-5) & SparseCategoricalCrossentropy\n",
      "ğŸ”¥ Training with smaller batch & selective unfreezing...\n",
      "Epoch 1/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 119ms/step - accuracy: 0.5370 - loss: 1.3419\n",
      "Epoch 1: val_accuracy improved from -inf to 0.77848, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_final_stable.keras\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m498s\u001b[0m 128ms/step - accuracy: 0.5370 - loss: 1.3419 - val_accuracy: 0.7785 - val_loss: 0.6790 - learning_rate: 1.0000e-05\n",
      "Epoch 2/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.5921 - loss: 1.1760\n",
      "Epoch 2: val_accuracy did not improve from 0.77848\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 119ms/step - accuracy: 0.5921 - loss: 1.1760 - val_accuracy: 0.7599 - val_loss: 0.7412 - learning_rate: 1.0000e-05\n",
      "Epoch 3/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6044 - loss: 1.1325\n",
      "Epoch 3: val_accuracy improved from 0.77848 to 0.80021, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_final_stable.keras\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 120ms/step - accuracy: 0.6044 - loss: 1.1325 - val_accuracy: 0.8002 - val_loss: 0.5998 - learning_rate: 1.0000e-05\n",
      "Epoch 4/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6103 - loss: 1.1025\n",
      "Epoch 4: val_accuracy improved from 0.80021 to 0.80715, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_final_stable.keras\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 120ms/step - accuracy: 0.6103 - loss: 1.1025 - val_accuracy: 0.8072 - val_loss: 0.5612 - learning_rate: 1.0000e-05\n",
      "Epoch 5/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6199 - loss: 1.0769\n",
      "Epoch 5: val_accuracy did not improve from 0.80715\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m393s\u001b[0m 120ms/step - accuracy: 0.6199 - loss: 1.0769 - val_accuracy: 0.8019 - val_loss: 0.5677 - learning_rate: 1.0000e-05\n",
      "Epoch 6/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6252 - loss: 1.0664\n",
      "Epoch 6: val_accuracy improved from 0.80715 to 0.80896, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_final_stable.keras\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 120ms/step - accuracy: 0.6252 - loss: 1.0664 - val_accuracy: 0.8090 - val_loss: 0.5628 - learning_rate: 1.0000e-05\n",
      "Epoch 7/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6319 - loss: 1.0369\n",
      "Epoch 7: val_accuracy improved from 0.80896 to 0.81877, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_final_stable.keras\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 121ms/step - accuracy: 0.6319 - loss: 1.0369 - val_accuracy: 0.8188 - val_loss: 0.5406 - learning_rate: 1.0000e-05\n",
      "Epoch 8/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6287 - loss: 1.0457\n",
      "Epoch 8: val_accuracy improved from 0.81877 to 0.83658, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_final_stable.keras\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 120ms/step - accuracy: 0.6287 - loss: 1.0457 - val_accuracy: 0.8366 - val_loss: 0.4898 - learning_rate: 1.0000e-05\n",
      "Epoch 9/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6458 - loss: 1.0102\n",
      "Epoch 9: val_accuracy did not improve from 0.83658\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 119ms/step - accuracy: 0.6458 - loss: 1.0102 - val_accuracy: 0.8349 - val_loss: 0.5146 - learning_rate: 1.0000e-05\n",
      "Epoch 10/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6403 - loss: 1.0070\n",
      "Epoch 10: val_accuracy improved from 0.83658 to 0.84065, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_final_stable.keras\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 120ms/step - accuracy: 0.6404 - loss: 1.0070 - val_accuracy: 0.8407 - val_loss: 0.4668 - learning_rate: 1.0000e-05\n",
      "Epoch 11/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6501 - loss: 1.0069\n",
      "Epoch 11: val_accuracy improved from 0.84065 to 0.84850, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_final_stable.keras\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 120ms/step - accuracy: 0.6501 - loss: 1.0069 - val_accuracy: 0.8485 - val_loss: 0.4525 - learning_rate: 1.0000e-05\n",
      "Epoch 12/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6538 - loss: 0.9818\n",
      "Epoch 12: val_accuracy did not improve from 0.84850\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m392s\u001b[0m 119ms/step - accuracy: 0.6538 - loss: 0.9818 - val_accuracy: 0.8322 - val_loss: 0.5293 - learning_rate: 1.0000e-05\n",
      "Epoch 13/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6485 - loss: 0.9871\n",
      "Epoch 13: val_accuracy did not improve from 0.84850\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 120ms/step - accuracy: 0.6485 - loss: 0.9871 - val_accuracy: 0.8434 - val_loss: 0.4801 - learning_rate: 1.0000e-05\n",
      "Epoch 14/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 113ms/step - accuracy: 0.6614 - loss: 0.9695\n",
      "Epoch 14: val_accuracy did not improve from 0.84850\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m394s\u001b[0m 120ms/step - accuracy: 0.6614 - loss: 0.9695 - val_accuracy: 0.8088 - val_loss: 0.7788 - learning_rate: 1.0000e-05\n",
      "Epoch 15/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6579 - loss: 0.9714\n",
      "Epoch 15: val_accuracy did not improve from 0.84850\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 120ms/step - accuracy: 0.6579 - loss: 0.9714 - val_accuracy: 0.8485 - val_loss: 0.4440 - learning_rate: 1.0000e-05\n",
      "Epoch 16/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6579 - loss: 0.9656\n",
      "Epoch 16: val_accuracy improved from 0.84850 to 0.85046, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_final_stable.keras\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 121ms/step - accuracy: 0.6579 - loss: 0.9656 - val_accuracy: 0.8505 - val_loss: 0.4351 - learning_rate: 1.0000e-05\n",
      "Epoch 17/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6651 - loss: 0.9496\n",
      "Epoch 17: val_accuracy improved from 0.85046 to 0.85891, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_final_stable.keras\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 121ms/step - accuracy: 0.6651 - loss: 0.9496 - val_accuracy: 0.8589 - val_loss: 0.4243 - learning_rate: 1.0000e-05\n",
      "Epoch 18/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6651 - loss: 0.9541\n",
      "Epoch 18: val_accuracy improved from 0.85891 to 0.86132, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_final_stable.keras\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 121ms/step - accuracy: 0.6651 - loss: 0.9541 - val_accuracy: 0.8613 - val_loss: 0.4041 - learning_rate: 1.0000e-05\n",
      "Epoch 19/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6677 - loss: 0.9405\n",
      "Epoch 19: val_accuracy improved from 0.86132 to 0.86148, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_final_stable.keras\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m398s\u001b[0m 121ms/step - accuracy: 0.6677 - loss: 0.9405 - val_accuracy: 0.8615 - val_loss: 0.4166 - learning_rate: 1.0000e-05\n",
      "Epoch 20/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6728 - loss: 0.9229\n",
      "Epoch 20: val_accuracy did not improve from 0.86148\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 120ms/step - accuracy: 0.6728 - loss: 0.9229 - val_accuracy: 0.8580 - val_loss: 0.4121 - learning_rate: 1.0000e-05\n",
      "Epoch 21/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6710 - loss: 0.9279\n",
      "Epoch 21: val_accuracy did not improve from 0.86148\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 120ms/step - accuracy: 0.6710 - loss: 0.9279 - val_accuracy: 0.8491 - val_loss: 0.4513 - learning_rate: 1.0000e-05\n",
      "Epoch 22/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6722 - loss: 0.9386\n",
      "Epoch 22: ReduceLROnPlateau reducing learning rate to 2.9999999242136253e-06.\n",
      "\n",
      "Epoch 22: val_accuracy did not improve from 0.86148\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 120ms/step - accuracy: 0.6722 - loss: 0.9386 - val_accuracy: 0.8159 - val_loss: 1.1974 - learning_rate: 1.0000e-05\n",
      "Epoch 23/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6803 - loss: 0.9051\n",
      "Epoch 23: val_accuracy improved from 0.86148 to 0.87717, saving model to /kaggle/working/checkpoints/resnet50_cbam_mha_final_stable.keras\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m397s\u001b[0m 121ms/step - accuracy: 0.6803 - loss: 0.9051 - val_accuracy: 0.8772 - val_loss: 0.3768 - learning_rate: 3.0000e-06\n",
      "Epoch 24/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6877 - loss: 0.8869\n",
      "Epoch 24: val_accuracy did not improve from 0.87717\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m396s\u001b[0m 120ms/step - accuracy: 0.6877 - loss: 0.8869 - val_accuracy: 0.8696 - val_loss: 0.3993 - learning_rate: 3.0000e-06\n",
      "Epoch 25/25\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 114ms/step - accuracy: 0.6930 - loss: 0.8690\n",
      "Epoch 25: val_accuracy did not improve from 0.87717\n",
      "\u001b[1m3285/3285\u001b[0m \u001b[32mâ”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”â”\u001b[0m\u001b[37m\u001b[0m \u001b[1m395s\u001b[0m 120ms/step - accuracy: 0.6930 - loss: 0.8690 - val_accuracy: 0.8672 - val_loss: 0.4183 - learning_rate: 3.0000e-06\n",
      "Restoring model weights from the end of the best epoch: 23.\n",
      "\n",
      "ğŸ“Š Evaluating final fine-tuned model...\n",
      "\n",
      "ğŸ“‹ Classification Report (Auto-Aligned Classes):\n",
      "\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "     disgust     0.6020    0.5576    0.5789       217\n",
      "        fear     0.6702    0.5311    0.5926       241\n",
      "       happy     0.8996    0.9148    0.9071      1185\n",
      "     neutral     0.9212    0.9280    0.9246      3277\n",
      "         sad     0.7902    0.7406    0.7646       478\n",
      "    surprise     0.8516    0.8828    0.8670      1229\n",
      "\n",
      "   micro avg     0.8781    0.8772    0.8776      6627\n",
      "   macro avg     0.7891    0.7591    0.7725      6627\n",
      "weighted avg     0.8754    0.8772    0.8758      6627\n",
      "\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 800x600 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "ğŸ Final Overall Accuracy (Computed from Confusion Matrix): 87.72%\n",
      "\n",
      "âœ… Model evaluation complete. Final model path: /kaggle/working/checkpoints/resnet50_cbam_mha_final_stable.keras\n"
     ]
    }
   ],
   "source": [
    "# === Block 5: Final Stable Fine-Tuning (ResNet50 + CBAM + MHA) ===\n",
    "import os, tensorflow as tf, numpy as np, matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix\n",
    "\n",
    "print(\"ğŸš€ Starting Final Fine-Tuning for ResNet50 CBAM MHA Model\")\n",
    "\n",
    "# 1ï¸âƒ£ --- Safety & GPU optimization ---\n",
    "os.environ[\"TF_CPP_MIN_LOG_LEVEL\"] = \"2\"  # reduce log noise\n",
    "try:\n",
    "    tf.config.optimizer.set_jit(False)  # disable XLA constant folding stalls\n",
    "except Exception:\n",
    "    pass\n",
    "\n",
    "# enable mixed precision (reduce memory usage)\n",
    "try:\n",
    "    from tensorflow.keras import mixed_precision\n",
    "    mixed_precision.set_global_policy(\"mixed_float16\")\n",
    "    print(\"âœ… Mixed precision enabled.\")\n",
    "except Exception as e:\n",
    "    print(\"âš ï¸ Mixed precision unavailable:\", e)\n",
    "\n",
    "# enable memory growth (prevents full GPU allocation)\n",
    "gpus = tf.config.list_physical_devices('GPU')\n",
    "for gpu in gpus:\n",
    "    try:\n",
    "        tf.config.experimental.set_memory_growth(gpu, True)\n",
    "        print(\"âœ… Memory growth enabled for\", gpu)\n",
    "    except:\n",
    "        pass\n",
    "\n",
    "# 2ï¸âƒ£ --- Unfreeze top layers safely ---\n",
    "UNFREEZE_LAYERS = 40\n",
    "for layer in model.layers[:-UNFREEZE_LAYERS]:\n",
    "    layer.trainable = False\n",
    "for layer in model.layers[-UNFREEZE_LAYERS:]:\n",
    "    if not isinstance(layer, tf.keras.layers.BatchNormalization):\n",
    "        layer.trainable = True\n",
    "\n",
    "print(f\"ğŸ”“ Unfroze top {UNFREEZE_LAYERS} layers for fine-tuning\")\n",
    "\n",
    "# 3ï¸âƒ£ --- Lower batch size & re-create datasets ---\n",
    "BATCH_SIZE = 8  # safe for 6â€“16 GB GPUs\n",
    "if 'make_dataset' in globals():\n",
    "    train_ds = make_dataset(image_paths, augment=True)\n",
    "    val_ds = make_dataset(val_paths, augment=False)\n",
    "else:\n",
    "    print(\"âš ï¸ make_dataset() not found, using existing train_ds/val_ds\")\n",
    "\n",
    "# 4ï¸âƒ£ --- Recompile model ---\n",
    "optimizer = tf.keras.optimizers.Adam(learning_rate=1e-5)\n",
    "loss_fn = tf.keras.losses.SparseCategoricalCrossentropy(from_logits=False)\n",
    "model.compile(optimizer=optimizer, loss=loss_fn, metrics=['accuracy'])\n",
    "print(\"âœ… Model recompiled with Adam (1e-5) & SparseCategoricalCrossentropy\")\n",
    "\n",
    "# 5ï¸âƒ£ --- Callbacks ---\n",
    "CKPT_DIR = CKPT_DIR if 'CKPT_DIR' in globals() else \"/kaggle/working/checkpoints\"\n",
    "os.makedirs(CKPT_DIR, exist_ok=True)\n",
    "MODEL_SAVE_FINAL = os.path.join(CKPT_DIR, \"resnet50_cbam_mha_final_stable.keras\")\n",
    "\n",
    "callbacks = [\n",
    "    tf.keras.callbacks.EarlyStopping(monitor=\"val_accuracy\", patience=8, restore_best_weights=True, verbose=1),\n",
    "    tf.keras.callbacks.ReduceLROnPlateau(monitor=\"val_loss\", factor=0.3, patience=4, min_lr=1e-7, verbose=1),\n",
    "    tf.keras.callbacks.ModelCheckpoint(MODEL_SAVE_FINAL, monitor=\"val_accuracy\", save_best_only=True, verbose=1)\n",
    "]\n",
    "\n",
    "# 6ï¸âƒ£ --- Start fine-tuning ---\n",
    "print(\"ğŸ”¥ Training with smaller batch & selective unfreezing...\")\n",
    "history_final = model.fit(\n",
    "    train_ds,\n",
    "    validation_data=val_ds,\n",
    "    epochs=25,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# === Final Evaluation + Confusion Matrix + Final Accuracy ===\n",
    "import numpy as np, matplotlib.pyplot as plt\n",
    "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
    "\n",
    "print(\"\\nğŸ“Š Evaluating final fine-tuned model...\\n\")\n",
    "\n",
    "y_true, y_pred = [], []\n",
    "for x_batch, y_batch in val_ds:\n",
    "    preds = model.predict(x_batch, verbose=0)\n",
    "    y_true.extend(y_batch.numpy().tolist())\n",
    "    y_pred.extend(np.argmax(preds, axis=1).tolist())\n",
    "\n",
    "# Auto-detect which classes are actually present in validation set\n",
    "unique_labels = sorted(np.unique(y_true))\n",
    "used_names = [CLASS_LIST[i] for i in unique_labels]\n",
    "\n",
    "# --- Classification Report ---\n",
    "print(\"ğŸ“‹ Classification Report (Auto-Aligned Classes):\\n\")\n",
    "print(classification_report(\n",
    "    y_true, y_pred,\n",
    "    labels=unique_labels,\n",
    "    target_names=used_names,\n",
    "    digits=4\n",
    "))\n",
    "\n",
    "# --- Confusion Matrix ---\n",
    "cm = confusion_matrix(y_true, y_pred, labels=unique_labels)\n",
    "plt.figure(figsize=(8,6))\n",
    "plt.imshow(cm, cmap=\"Blues\")\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.colorbar()\n",
    "plt.xticks(range(len(used_names)), used_names, rotation=45)\n",
    "plt.yticks(range(len(used_names)), used_names)\n",
    "plt.xlabel(\"Predicted\")\n",
    "plt.ylabel(\"True\")\n",
    "plt.tight_layout()\n",
    "plt.show()\n",
    "\n",
    "# --- Final Overall Accuracy ---\n",
    "final_acc = accuracy_score(y_true, y_pred) * 100\n",
    "print(f\"\\nğŸ Final Overall Accuracy (Computed from Confusion Matrix): {final_acc:.2f}%\")\n",
    "\n",
    "print(f\"\\nâœ… Model evaluation complete. Final model path: {MODEL_SAVE_FINAL}\")\n"
   ]
  }
 ],
 "metadata": {
  "kaggle": {
   "accelerator": "nvidiaTeslaT4",
   "dataSources": [
    {
     "datasetId": 8560175,
     "sourceId": 13483086,
     "sourceType": "datasetVersion"
    }
   ],
   "dockerImageVersionId": 31154,
   "isGpuEnabled": true,
   "isInternetEnabled": true,
   "language": "python",
   "sourceType": "notebook"
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  },
  "papermill": {
   "default_parameters": {},
   "duration": 19554.606786,
   "end_time": "2025-11-06T09:45:02.199245",
   "environment_variables": {},
   "exception": null,
   "input_path": "__notebook__.ipynb",
   "output_path": "__notebook__.ipynb",
   "parameters": {},
   "start_time": "2025-11-06T04:19:07.592459",
   "version": "2.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
